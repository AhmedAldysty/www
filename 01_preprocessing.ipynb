{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "new_txt = []\n",
    "file_name = 'A2.txt'\n",
    "processed_file_name = 'A2_processed.txt'\n",
    "with open(file_name, 'r') as ori_file:\n",
    "    with open(processed_file_name, 'w') as proced_file:\n",
    "        for i, line in enumerate(ori_file):\n",
    "            if len(line)>57:\n",
    "                new_line = line[:56]+'\\n'\n",
    "            else:\n",
    "                new_line = line            \n",
    "            proced_file.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "file_name = 'A2.txt'\n",
    "processed_file_name = 'A2_processed.txt'\n",
    "csv_name = 'A2_processed_cleaned.csv'\n",
    " \n",
    "data = []\n",
    "chunk = []\n",
    "row = 0\n",
    " \n",
    "with open(file_name, 'r') as ori_file:\n",
    "    with open(processed_file_name, 'w') as proced_file:\n",
    "        for i, line in enumerate(ori_file):\n",
    "            if len(line)>57:\n",
    "                new_line = line[6:56]+'\\n'\n",
    "            else:\n",
    "                new_line = line[6:]\n",
    "            if line == '\\n':\n",
    "                if len(chunk)>300:\n",
    "                    print(f\"rwo:{row}, len(chunk):{len(chunk)}\")\n",
    "                data.append(chunk)\n",
    "                row +=1\n",
    "                chunk = []\n",
    "            else:\n",
    "                new_line = new_line.strip()\n",
    "                chunk += new_line.split(' ')\n",
    " \n",
    "df = pd.DataFrame(data)    \n",
    "df.to_csv(csv_name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'A2_processed_cleaned.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the first 54 columns (just extract the Modbus Packets)\n",
    "df = df.iloc[:, 54:]\n",
    "\n",
    "# Optionally, save the modified DataFrame to a new CSV file\n",
    "df.to_csv('A2_processed_cleaned2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file\n",
    "df1 = pd.read_csv('information.csv')\n",
    "\n",
    "# Load the second CSV file\n",
    "df2 = pd.read_csv('A2_processed_cleaned2.csv')\n",
    "\n",
    "# Concatenate the two dataframes side by side\n",
    "combined_df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "combined_df.to_csv('A2_processed_cleaned2_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('A2_processed_cleaned2_combined.csv')\n",
    "\n",
    "# Specify the column name\n",
    "column_name = 'Info'  # Replace with the actual column name\n",
    "\n",
    "# Filter the DataFrame to keep only rows containing \"Query\"\n",
    "filtered_df = df[df[column_name].str.contains('Query', case=False, na=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_df.to_csv('A2_processed_cleaned2_combined_filtered_file_final(Query).csv', index=False)\n",
    "\n",
    "# Optionally, print the filtered DataFrame to verify the results\n",
    "#print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def extract_hex_data_from_log(log_filename):\n",
    "    hex_data_list = []\n",
    "    send_pattern = re.compile(r'SEND: (.*)')  # Regex pattern to match the SEND lines and capture hex data\n",
    "\n",
    "    with open(log_filename, 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            match = send_pattern.search(line)\n",
    "            if match:\n",
    "                hex_data = match.group(1)  # Extract the hexadecimal data\n",
    "                hex_data_list.append(hex_data)\n",
    "    \n",
    "    return hex_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hex_data_to_csv(hex_data_list, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"Hexadecimal Data\"])  # Write the header\n",
    "        for hex_data in hex_data_list:\n",
    "            writer.writerow([hex_data])  # Write each hex data as a new row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the names of your input and output CSV files\n",
    "input_csv_name = 'hex_data_final.csv'  \n",
    "output_csv_name = 'hex_data_final_processed.csv'  \n",
    "\n",
    "# Read the original CSV file\n",
    "df = pd.read_csv(input_csv_name)\n",
    "\n",
    "\n",
    "packet_column_index = 0  \n",
    "\n",
    "# Process each row in the dataframe\n",
    "processed_data = []\n",
    "for index, row in df.iterrows():\n",
    "    packet = row[packet_column_index]  # Get the packet from the specified column\n",
    "    bytes_list = packet.split()  # Split the packet into individual bytes\n",
    "    processed_data.append(bytes_list)  # Append the list of bytes as a new row in the processed data\n",
    "\n",
    "# Create a new dataframe from the processed data\n",
    "processed_df = pd.DataFrame(processed_data)\n",
    "\n",
    "# Write the processed dataframe to a new CSV file\n",
    "processed_df.to_csv(output_csv_name, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "import csv\n",
    "\n",
    "def pad_csv_rows(input_file, output_file):\n",
    "    # Read all rows from the input CSV file\n",
    "    with open(input_file, 'r', newline='') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Find the maximum row length\n",
    "    max_length = max(len(row) for row in rows)\n",
    "\n",
    "    # Pad each row to the maximum length\n",
    "    padded_rows = [row + [''] * (max_length - len(row)) for row in rows]\n",
    "\n",
    "    # Write the padded rows to the output CSV file\n",
    "    with open(output_file, 'w', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerows(padded_rows)\n",
    "\n",
    "# Example usage\n",
    "input_file = 'A2_processed_cleaned2_combined_filtered_file_final(Query).csv'\n",
    "output_file = 'A2_processed_cleaned2_combined_filtered_file_padded_final(Query).csv'\n",
    "pad_csv_rows(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert hexadecimal to decimal\n",
    "import pandas as pd\n",
    "\n",
    "def hex_to_decimal(hex_str):\n",
    "    \n",
    "    return int(hex_str, 16)\n",
    "\n",
    "\n",
    "input_csv_name = 'A2_processed_cleaned2_combined_filtered_file_padded_final(Query).csv'  \n",
    "output_csv_name = 'data_final.csv'  \n",
    "\n",
    "# Read the input CSV file\n",
    "df = pd.read_csv(input_csv_name)\n",
    "\n",
    "# Apply the conversion to each cell in the DataFrame\n",
    "converted_df = df.applymap(lambda cell: hex_to_decimal(cell) if pd.notnull(cell) else cell)\n",
    "\n",
    "# Write the converted DataFrame to a new CSV file\n",
    "converted_df.to_csv(output_csv_name, index=False)\n",
    "\n",
    "print(f\"Conversion complete. Decimal values saved to '{output_csv_name}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
